{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG over multiple documents\n",
    "TODO\n",
    "- Add more documents\n",
    "- Maybe use summary tool to auto-generate summaries\n",
    "- Persist for every doc the index as well as the generated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_OPENAI = False\n",
    "\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "if USE_OPENAI:\n",
    "    Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "else:\n",
    "    Settings.llm = Ollama(model=\"llama3:instruct\", request_timeout=120.0)\n",
    "    Settings.embed_model = OllamaEmbedding(\n",
    "        model_name=\"llama3:instruct\",\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        ollama_additional_kwargs={\"mirostat\": 0})\n",
    "\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files=[\n",
    "    \"../data/idpp.pdf\", \"../data/metagpt.pdf\", \"../data/state_of_the_union.txt\", \"../data/Federal Tax Return 2021.pdf\",\n",
    "    \"../data/Financial Assessment.docx\", \"../data/IELTS Result - March 2023.pdf\", \"../data/Shashank Verma - Resume.pdf\"]#,  \"../data/Income Tax Return Transcript 2020.pdf\"]\n",
    "\n",
    "file_summaries = [\n",
    "    \"Useful for retrieving specific context from the iDPP paper which is about predicting ALSFRS-R rating scores for ALS patients.\",\n",
    "    \"Useful for retrieving specific context from the MetaGPT paper.\",\n",
    "    \"Useful for retrieving specific context from the state of the union speech by the president.\",\n",
    "    \"Useful for retrieving specific context from the Federal Tax Return of 2021 detailing things like gross income, taxable income, tax paid and so on\",\n",
    "    \"Useful for retrieving specific context from Financial Assessment detailing how much to spend per month on various things\",\n",
    "    \"Useful for retrieving specific context from my IELTS result I got in 2023 denoting my English speaking skills\",\n",
    "    \"Useful for retrieving specific context from my resume specifying what projects I've worked on, where I studied, what my qualifications are, etc\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving vector_index for idpp from storage\n",
      "Retrieving vector_index for metagpt from storage\n",
      "Retrieving vector_index for state_of_the_union from storage\n",
      "Creating vector_index for Federal Tax Return 2021\n",
      "Creating vector_index for Financial Assessment\n",
      "Creating vector_index for IELTS Result - March 2023\n",
      "Creating vector_index for Shashank Verma - Resume\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "vector_indices = []\n",
    "for file in input_files:\n",
    "    filename = os.path.basename(file).split('.')[0]\n",
    "    # Read from storage if using OPENAI and the embeddings exist\n",
    "    if USE_OPENAI and os.path.exists(f\"file_embeddings/openAI/{filename}\"):\n",
    "        print (f\"Retrieving vector_index for {filename} from storage\")\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=f\"file_embeddings/openAI/{filename}\")\n",
    "        vector_index = load_index_from_storage(storage_context=storage_context)\n",
    "    # Otherwise create index using regular method\n",
    "    else:\n",
    "        print (f\"Creating vector_index for {filename}\")\n",
    "        loader = SimpleDirectoryReader(input_files=[file])\n",
    "        documents = loader.load_data()\n",
    "\n",
    "        # splitter = Settings.node_parser\n",
    "        # nodes = splitter.get_nodes_from_documents(documents)\n",
    "        # index = VectorStoreIndex(nodes)\n",
    "        vector_index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "    vector_indices.append(vector_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving vector_index for idpp\n",
      "Saving vector_index for metagpt\n",
      "Saving vector_index for state_of_the_union\n",
      "Saving vector_index for Federal Tax Return 2021\n",
      "Saving vector_index for Financial Assessment\n",
      "Saving vector_index for IELTS Result - March 2023\n",
      "Saving vector_index for Shashank Verma - Resume\n"
     ]
    }
   ],
   "source": [
    "if USE_OPENAI:\n",
    "    for i in range(len(input_files)):\n",
    "        filename = os.path.basename(input_files[i]).split('.')[0]\n",
    "        print (f\"Saving vector_index for {filename}\")\n",
    "        vector_indices[i].storage_context.persist(f\"file_embeddings/openAI/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "query_engine_tools = []\n",
    "for i in range(len(input_files)):\n",
    "    query_engine_tools.append(QueryEngineTool.from_defaults(\n",
    "        query_engine=vector_indices[i].as_query_engine(),\n",
    "        description=file_summaries[i],\n",
    "    ))\n",
    "\n",
    "len(query_engine_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using ToolRetrieverRouterQueryEngine\n",
    "# from llama_index.core import VectorStoreIndex\n",
    "# from llama_index.core.objects import ObjectIndex\n",
    "# from llama_index.core.query_engine import ToolRetrieverRouterQueryEngine\n",
    "\n",
    "# obj_index = ObjectIndex.from_objects(query_engine_tools, index_cls=VectorStoreIndex)\n",
    "# query_engine = ToolRetrieverRouterQueryEngine(obj_index.as_retriever())\n",
    "\n",
    "# response = query_engine.query(\"What do the authors say in iDPP paper\")\n",
    "# print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RouterQueryEngine\n",
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=query_engine_tools,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The iDPP paper is specifically mentioned in choice 1, indicating that it is relevant for retrieving specific context from the iDPP paper..\n",
      "\u001b[0mThe authors in the iDPP paper discuss their approach to predicting ALSFRS-R scores using various techniques, starting with a naive model as a baseline and then exploring different Machine Learning algorithms for regression, along with a Long Short-Term Memory (LSTM) neural network to capture temporal dependencies in sequential sensor data. They evaluate the performance of these models using Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) metrics. The paper also covers related work in the field, the methodology employed, experimental results, implications of their findings, future work directions, and concludes the study.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What do the authors say in iDPP paper\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The iDPP paper is specifically mentioned in choice 1, which is about predicting ALSFRS-R rating scores for ALS patients. This makes it the most relevant choice for the question about models tried for predicting ALS progression in the iDPP paper..\n",
      "\u001b[0mThe models tried for predicting ALS progression in the idpp paper included a naive model that carried the last observed value forward, various Machine Learning algorithms for regression, and a Long Short-Term Memory (LSTM) neural network to capture temporal dependencies in the sequential sensor data.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What were the models tried for predicting ALS progression in the idpp paper?.\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The iDPP paper is specifically mentioned in choice 1, indicating that it is relevant to retrieving specific context from the paper, which would likely include details about the validation strategy used by the authors..\n",
      "\u001b[0mGrid search using cross validation on the entire training data was the validation strategy used by the authors in the idpp paper.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was the validation strategy used by the authors in the idpp paper?.\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The iDPP paper is specifically mentioned in choice 1, making it the most relevant option for retrieving specific context about the model performance in the iDPP paper..\n",
      "\u001b[0mThe ElasticNet model performed the best with the lowest RMSE in the idpp paper.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Which model performed the best with lowest RMSE in the idpp paper?.\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 2: The State of the Union speech by the president is likely to contain information about Justice Breyer.\n",
      "\u001b[0mThe president honored Justice Breyer for his service to the country, acknowledging him as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the president say about Justice Breyer\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: MetaGPT paper is likely to contain information on how MetaGPT agents share information with other agents..\n",
      "\u001b[0mMetaGPT agents share information with other agents by utilizing a shared message pool. This pool allows agents to exchange messages directly, publish structured messages, and access information from other entities transparently. Agents can retrieve required information from the shared pool without needing to inquire about other agents or wait for their responses, thereby enhancing communication efficiency.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How do MetaGPT agents share information with other agents?\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 5: The IELTS exam is specifically mentioned in choice 6, which is about retrieving specific context from the IELTS result..\n",
      "\u001b[0mYour reading score in the IELTS exam was 8.5.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was my reading score in IELTS exam?\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 6: My resume specifies where I studied, which is relevant to my educational background..\n",
      "\u001b[0mYou have completed an Artificial Intelligence Professional Program at Stanford University from May 2021 to August 2022, and you also hold a Bachelor's degree in Computer Science and Engineering from the Indian Institute of Technology, Delhi, New Delhi, from July 2009 to May 2013.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is my educational background according to my resume?\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 4: Financial Assessment detailing how much to spend per month on various things.\n",
      "\u001b[0mYou can expect to spend $500 per month on Hobbies.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How much do I expect to spend per month on Hobbies?\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 3: The Federal Tax Return of 2021 detailing things like gross income, taxable income, tax paid and so on would be the most relevant choice for retrieving information about the total tax amount to be paid in 2021..\n",
      "\u001b[0mYour total tax amount to be paid in 2021 was $207,117.00.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was my total tax amount to be paid in 2021?\")\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 3: The Federal Tax Return of 2021 would detail your gross income for that year..\n",
      "\u001b[0mYour total gross income in 2021 was $746,812.00.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was my total gross income in 2021?\")\n",
    "print (response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
