{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on:\n",
    "https://docs.llamaindex.ai/en/stable/presentations/materials/2024-02-28-rag-bootcamp-vector-institute/?h=rag\n",
    "\n",
    "- If using Ollama LLM and embeddings, feel free to use this notebook as is by setting USE_OPENAI = False\n",
    "- If using OpenAI LLM and embeddings, use the llamaindex_using_pickledata.ipynb since that will save requesting embeddings again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_OPENAI = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "if USE_OPENAI:\n",
    "    Settings.llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "else:\n",
    "    Settings.llm = Ollama(model=\"llama3:instruct\")\n",
    "    Settings.embed_model = OllamaEmbedding(\n",
    "        model_name=\"llama3:instruct\",\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        ollama_additional_kwargs={\"mirostat\": 0},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the data.\n",
    "\n",
    "With llama-index, before any transformations are applied,\n",
    "data is loaded in the `Document` abstraction, which is\n",
    "a container that holds the text of the document.\n",
    "\"\"\"\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "loader = SimpleDirectoryReader(input_files=[\"./data/idpp.pdf\", \"./data/metagpt.pdf\", \"./data/state_of_the_union.txt\"]) # input_dir=\"./data\")\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to see what the text looks like\n",
    "# print (documents[0].text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Payload indexes have no effect in the local Qdrant. Please use server Qdrant if you need payload indexes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Chunk, Encode, and Store into a Vector Store.\n",
    "\n",
    "To streamline the process, we can make use of the IngestionPipeline\n",
    "class that will apply your specified transformations to the\n",
    "Document's.\n",
    "\"\"\"\n",
    "\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "import qdrant_client\n",
    "\n",
    "client = qdrant_client.QdrantClient(location=\":memory:\")\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"test_store\")\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        Settings.embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "_nodes = pipeline.run(documents=documents, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "# if you want to see the nodes\n",
    "print (len(_nodes))\n",
    "# print (_nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a llama-index... wait for it... Index.\n",
    "\n",
    "After uploading your encoded documents into your vector\n",
    "store of choice, you can connect to it with a VectorStoreIndex\n",
    "which then gives you access to all of the llama-index functionality.\n",
    "\"\"\"\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Retrieve relevant documents against a query.\n",
    "\n",
    "With our Index ready, we can now query it to\n",
    "retrieve the most relevant document chunks.\n",
    "\"\"\"\n",
    "\n",
    "retriever = index.as_retriever(similarity_top_k=2)\n",
    "retrieved_nodes = retriever.retrieve(\"What did the president say about Justice Breyer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And he loved building Legos with their daughter. But cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body.\n",
      "\n",
      "Danielle says Heath was a fighter to the very end. He didn’t know how to stop fighting, and neither did she.\n",
      "\n",
      "Through her pain, she found purpose to demand that we do better. Tonight, Danielle, we are going to do better.\n",
      "\n",
      "The VA — the VA is pioneering new ways of linking toxic exposures to disease, already helping more veterans get benefits. And tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers.\n",
      "\n",
      "I’m also calling on Congress to pass a law to make sure veterans devastated by toxic exposure in Iraq and Afghanistan finally get the benefits and the comprehensive healthcare they deserve.\n",
      "\n",
      "And fourth and last, let’s end cancer as we know it. This is personal. This is personal to me and to Jill and to Kamala and so many of you. So many of you have lost someone you love — husband, wife, son, daughter, mom, dad.\n",
      "\n",
      "Cancer is the number-two cause of death in America, second only to heart disease.\n",
      "\n",
      "Last month, I announced the plan to supercharge the Cancer Moonshot that President Obama asked me to lead six years ago.\n",
      "\n",
      "Our goal is to cut cancer death rates by at least 50 percent over the next 25 years. And I think we can do better than that: turn cancers from death sentences into treatable diseases, more support for patients and families.\n",
      "\n",
      "To get there, I call on Congress to fund what I called ARPA-H: Advanced — Advanced Research Projects Agency for Health. Patterned after DARPA in the Defense Department, projects that led — in DARPA — to the Internet, GPS, and so much more that make our forces more safer and be able to wage war more — with more clarity.\n",
      "\n",
      "ARPA-H will have a singular purpose to drive breakthroughs in cancer, Alzheimer’s, and diabetes, and more.\n",
      "\n",
      "A Unity Agenda for the nation. We can do these things. It’s within our power. And I don’t see a partisan edge to any one of those four things.\n",
      "\n",
      "My fellow Americans — tonight we’ve gathered in a sacred space: the citadel of democracy. In this Capitol, generation after generation of Americans have debated great questions amid great strife and have done great things.\n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. We built the strongest, freest, and most prosperous nation the world has ever known.\n",
      "\n",
      "Now is the hour: our moment of responsibility, our test of resolve and conscience of history itself. It is in this moment that our character of this generation is formed, our purpose is found, our future is forged.\n",
      "\n",
      "Well, I know this nation. We’ll meet the test, protect freedom and liberty, expand fairness and opportunity. And we will save democracy.\n",
      "\n",
      "As hard as those times have been, I’m more optimistic about America today than I’ve been my whole life because I see the future that’s within our grasp, because I know there is simply nothing beyond our camas- — our capacity.\n",
      "\n",
      "We’re the only nation on Earth that has always turned every crisis we’ve faced into an opportunity, the only nation that can be defined by a single word: possibilities.\n",
      "\n",
      "So, on this night, on our 245th year as a nation, I’ve come to report on the state of the nation — the state of the union. And my report is this: The State of the Union is strong because you, the American people, are strong.\n",
      "\n",
      "We are stronger today — we are stronger today than we were a year ago. And we’ll be stronger a year from now than we are today.\n",
      "\n",
      "This is our moment to meet and overcome the challenges of our time. And we will, as one people, one America — the United States of America.\n",
      "\n",
      "God bless you all. And may God protect our troops. Thank you. Go get ’em.\n",
      "================\n",
      "President Biden’s State of the Union Address\n",
      "Madam Speaker, Madam Vice President, and our First Lady and Second Gentleman, members of Congress and the Cabinet, Justices of the Supreme Court, my fellow Americans: Last year, COVID-19 kept us apart. This year, we’re finally together again.\n",
      "\n",
      "Tonight — tonight we meet as Democrats, Republicans, and independents, but, most importantly, as Americans with a duty to one another, to America, to the American people, and to the Constitution, and an unwavering resolve that freedom will always triumph over tyranny.\n",
      "\n",
      "Six — thank you. Six days ago, Russia’s Vladimir Putin sought to shake the very foundations of the free world, thinking he could make it bend to his menacing ways. But he badly miscalculated. He thought he could roll into Ukraine and the world would roll over. Instead, he met with a wall of strength he never anticipated or imagined. He met the Ukrainian people.\n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination literally inspires the world. Groups of citizens blocking tanks with their bodies. Everyone from students to retirees, to teachers turned soldiers defending their homeland.\n",
      "\n",
      "And in this struggle — President Zelenskyy said in his speech to the European Parliament, “Light will win over darkness.”\n",
      "\n",
      "The Ukrainian Ambassador to the United States is here tonight sitting with the First Lady. Let each of us, if you’re able to stand, stand and send an unmistakable signal to the world and Ukraine. Thank you. Thank you, thank you, thank you.\n",
      "\n",
      "She’s bright, she’s strong, and she’s resolved.\n",
      "\n",
      "Yes. We, the United States of America, stand with the Ukrainian people.\n",
      "\n",
      "Throughout our history, we’ve learned this lesson: When dictators do not pay a price for their aggression, they cause more chaos; they keep moving; and the costs, the threats to the America — and America, to the world keeps rising.\n",
      "\n",
      "That’s why the NATO Alliance was created: to secure peace and stability in Europe after World War Two.\n",
      "\n",
      "The United States is a member, along with 29 other nations. It matters. American diplomacy matters. American resolve matters.\n",
      "\n",
      "Putin’s latest attack on Ukraine was premeditated and totally unprovoked. He rejected repeated efforts at diplomacy.\n",
      "\n",
      "He thought the West and NATO wouldn’t respond. He thought he could divide us at home, in this chamber, in this nation. He thought he could divide us in Europe as well.\n",
      "\n",
      "But Putin was wrong. We are ready. We are united. And that’s what we did: We stayed united.\n",
      "\n",
      "We prepared extensively and carefully. We spent months building coalitions of other freedom-loving nations in Europe and the Americas to — from America to the Asian and African continents to confront Putin.\n",
      "\n",
      "Like many of you, I spent countless hours unifying our European Allies.\n",
      "\n",
      "We shared with the world, in advance, what we knew Putin was planning and precisely how he would try to falsely and justify his aggression.\n",
      "\n",
      "We countered Russia’s lies with the truth. And now — now that he’s acted, the free world is holding him accountable, along with 27 members of the European Union — including France, Germany, Italy — as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others. Even Switzerland are inflicting pain on Russia and supporting the people of Ukraine.\n",
      "\n",
      "Putin is now isolated from the world more than he has ever been.\n",
      "\n",
      "Together. Together. Together, along with our Allies, we are right now enforcing powerful economic sanctions. We’re cutting off Russia’s largest banks from the international financial system; preventing Russia’s Central Bank from defending the Russian ruble, making Putin’s $630 billion war fund worthless. We’re choking Russia’s access, we’re choking Russia’s access to technology that will sap its economic strength and weaken its military for years to come.\n",
      "\n",
      "Tonight, I say to the Russian oligarchs and the corrupt leaders who’ve bilked billions of dollars off this violent regime: No more.\n",
      "\n",
      "The United States — I mean it. The United States Department of Justice is assembling a dedicated task force to go after the crimes of the Russian oligarchs.\n",
      "\n",
      "We’re joining with European Allies to find and seize their yachts, their luxury apartments, their private jets. We’re coming for your ill-begotten gains.\n",
      "\n",
      "And, tonight, I’m announcing that we will join our Allies in closing off American air space to all Russian flights, further isolating Russia and adding an additional squeeze on their economy.\n",
      "\n",
      "He has no idea what’s coming.\n",
      "\n",
      "The ruble has already lost 30 percent of its value, the Russian stock market has lost 40 percent of its value, and trading remains suspended.\n",
      "\n",
      "The Russian economy is reeling, and Putin alone is the one to blame.\n"
     ]
    }
   ],
   "source": [
    "# to view the retrieved node\n",
    "print (retrieved_nodes[0].text)\n",
    "print (\"================\")\n",
    "print (retrieved_nodes[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Context-Augemented Generation.\n",
    "\n",
    "With our Index ready, we can create a QueryEngine\n",
    "that handles the retrieval and context augmentation\n",
    "in order to get the final response.\n",
    "\"\"\"\n",
    "\n",
    "query_engine = index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "# to inspect the default prompt being used\n",
    "print(\n",
    "    query_engine.get_prompts()[\n",
    "        \"response_synthesizer:text_qa_template\"\n",
    "    ].default_template.template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, various machine learning algorithms for regression, as well as a Long Short-Term Memory (LSTM) neural network, were implemented to model the temporal dependencies in the sequential sensor data. The specific models tried include:\n",
      "\n",
      "* Naive model\n",
      "* ElasticNet model\n",
      "* Lasso model\n",
      "* FS Model Q1-Q12\n",
      "\n",
      "These models were used to predict ALSFRS-R scores assigned by medical professionals using sensor data collected via a dedicated app, as part of Task 1 in the iDPP@CLEF 2024 competition.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What were the models tried for predicting ALS progression in the idpp paper?.\")\n",
    "print (response)\n",
    "# According to the provided context, several machine learning algorithms for regression as well as a Long Short-Term Memory (LSTM) neural network were explored to model the temporal dependencies in the sequential sensor data. The naive model was also tried, which simply carries the last observed value forward. Additionally, ElasticNet and Lasso models were used with different subsets of Task1 and Task2 data for training.\n",
    "# The models tried for predicting ALS progression in the iDPP paper included a naive model that carried the last observed value forward, various Machine Learning algorithms for regression, and a Long Short-Term Memory (LSTM) neural network to model the temporal dependencies in the sequential sensor data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation strategy used by the authors in the iDPP paper is not explicitly mentioned. However, based on the provided context, it can be inferred that the authors evaluated the performance of their models using Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) metrics, as identified by the challenge organizers. The authors also report the results of their experiments, comparing the performance of different models, which suggests a hold-out set or cross-validation approach was used for model evaluation.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What was the validation strategy used by the authors in the idpp paper?.\")\n",
    "print (response)\n",
    "# The validation strategy used by the authors in the iDPP paper is not explicitly mentioned. However, based on the provided context, it can be inferred that the authors evaluated the performance of their models using Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) metrics, as identified by the challenge organizers. The authors also report the results of their experiments, comparing the performance of different models, which suggests a hold-out set or cross-validation approach was used for model evaluation.\n",
    "# The authors in the idpp paper used a nested k-fold cross-validation strategy for their validation. This strategy consisted of two loops - an inner loop and an outer loop. In the inner loop, a test set containing 10% of complete patient data was set aside, while the remaining data underwent further k-fold cross-validation. This was adapted to ensure that each patient's complete set of observations was included in both the training and validation sets. The outer loop repeated the same procedure on another test set covering another 10% of the patients. This process was repeated for 10 iterations in the outer loop to compute RMSE for model selection. The best hyperparameters were chosen based on these iterations, and all the data was fit using those hyperparameters prior to the final submission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Table 2 in the provided context, the best-performing model for each of the 12 questions in ALSFRS-R scores is denoted by a green box. However, it's not specified which model performed the best overall with the lowest RMSE.\n",
      "\n",
      "To answer your query, I would recommend looking at the text or other tables in the paper to find the overall best-performing model. Alternatively, you could try contacting the authors of the paper for more information on their results.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Which model performed the best with lowest RMSE in the idpp paper?.\")\n",
    "print (response)\n",
    "# According to Table 2 in the provided context, the best-performing model for each of the 12 questions in ALSFRS-R scores is denoted by a green box. However, it's not specified which model performed the best overall with the lowest RMSE.\n",
    "# The ElasticNet + Naive model performed the best with the lowest RMSE in the iDPP paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to help! However, I must point out that there is no mention of a president or Justice Breyer in the provided context information. The text appears to be discussing a study on predicting ALSFRS-R scores based on time-series sensor data and machine learning models. Therefore, it's not possible for me to provide an answer about what the president said about Justice Breyer, as this information is not present in the given context.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What did the president say about Justice Breyer\")\n",
    "print (response)\n",
    "# I apologize, but there is no mention of a president or Justice Breyer in the provided context. The text appears to be discussing a study on predicting ALSFRS-R scores based on time-series sensor data and does not contain any information related to politics or justices. Therefore, I cannot provide an answer to this query as it is outside the scope of the given context.\n",
    "# The president expressed gratitude and appreciation for Justice Breyer's service to the country, acknowledging his dedication as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MetaGPT framework enables multi-agent collaboration by providing well-defined functions for role definition and message sharing. This allows agents to effectively share information and work together towards a common goal.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"How do agents share information with other agents in MetaGPT?\")\n",
    "print (response)\n",
    "# According to the provided context, MetaGPT is a meta-programming framework for multi-agent collaboration based on Large Language Models (LLMs). It has well-defined functions like role definition and message sharing, making it a useful platform for developing LLM-based multi-agent systems. However, it does not explicitly mention how agents share information with other agents.\n",
    "# Agents share information with other agents by utilizing a shared message pool. This shared message pool allows all agents to exchange messages directly. Agents publish their structured messages in the pool and can also access messages from other entities transparently. This system enables any agent to retrieve necessary information directly from the shared pool without having to inquire about other agents and wait for their responses, ultimately enhancing communication efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Store the vectore store's nodes which have the actual embeddings so we don't have to reuse OpenAIEmbeddings() everytime we run this. Cost savings.\n",
    "# with open('models/openAI_idpp_metagpt_state/_nodes.pickle', 'wb') as handle:\n",
    "#     pickle.dump(_nodes, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
