# learning-llm

Best to use llm-prompting-with-llama-api for all tasks esp when trying to incorporate it in places. Only use of llm-prompting-with-openai-api is for some sample usages of prompting best practices.

### llm-prompting-with-llama-api
- Samples on how to prompt Llama models using either TogetherAI or the local llama (via ollama)
- A few sample usages of prompting like summarizing, inferring, chatting, etc.

### llm-prompting-with-openai-api
- This uses local llama only (via ollama)
- Some examples of using prompts to accomplish tasks like summarizing, expanding, transforming, etc.

### rag
- Retrieval Augmented generation code
